#!/usr/bin/env python3
"""
ë°ì´í„° ë¶„í• 
- ì •ì œëœ ë°ì´í„°ë¥¼ train/validation/testë¡œ ë¶„í•  (6:2:2)
- ì¸µí™” ìƒ˜í”Œë§ìœ¼ë¡œ ê° ì„¸íŠ¸ì˜ í´ë˜ìŠ¤ ë¶„í¬ ìœ ì§€
"""

import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')

class DataSplitter:
    def __init__(self, input_path, output_path):
        self.input_path = Path(input_path)
        self.output_path = Path(output_path)
        self.output_path.mkdir(exist_ok=True)
        
        self.target_column = 'mortality_48h'
        
    def load_data(self):
        """ì •ì œëœ ë°ì´í„° ë¡œë“œ"""
        print("ğŸ“‚ ì •ì œëœ ë°ì´í„° ë¡œë”© ì¤‘...")
        df = pd.read_csv(self.input_path)
        
        print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {df.shape}")
        
        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        if self.target_column not in df.columns:
            raise ValueError(f"íƒ€ê²Ÿ ì»¬ëŸ¼({self.target_column})ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        return df
    
    def analyze_distribution(self, df, title="ë°ì´í„° ë¶„í¬"):
        """í´ë˜ìŠ¤ ë¶„í¬ ë¶„ì„"""
        print(f"\nğŸ“Š {title}")
        
        if self.target_column in df.columns:
            dist = df[self.target_column].value_counts().sort_index()
            total = len(df)
            mortality_rate = df[self.target_column].mean()
            
            print(f"   - ì „ì²´: {total:,}ëª…")
            print(f"   - ìƒì¡´ (0): {dist[0]:,}ëª… ({dist[0]/total:.1%})")
            print(f"   - ì‚¬ë§ (1): {dist[1]:,}ëª… ({dist[1]/total:.1%})")
            print(f"   - ì‚¬ë§ë¥ : {mortality_rate:.1%}")
            print(f"   - ë¶ˆê· í˜• ë¹„ìœ¨: {dist[0]/dist[1]:.1f}:1")
            
            return dist, mortality_rate
        
        return None, None
    
    def stratified_split(self, df, test_size=0.2, val_size=0.2, random_state=42):
        """ì¸µí™” ë¶„í•  (6:2:2)"""
        print(f"\nğŸ”„ ì¸µí™” ë¶„í•  ìˆ˜í–‰ ì¤‘...")
        print(f"   - Train: {1-test_size-val_size:.0%}")
        print(f"   - Validation: {val_size:.0%}")
        print(f"   - Test: {test_size:.0%}")
        
        # íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬
        X = df.drop(columns=[self.target_column])
        y = df[self.target_column]
        
        # 1ë‹¨ê³„: Train + Temp(Val+Test) ë¶„í• 
        temp_size = test_size + val_size
        X_train, X_temp, y_train, y_temp = train_test_split(
            X, y, 
            test_size=temp_size, 
            stratify=y, 
            random_state=random_state
        )
        
        # 2ë‹¨ê³„: Tempë¥¼ Validationê³¼ Testë¡œ ë¶„í• 
        val_ratio = val_size / temp_size
        X_test, X_val, y_test, y_val = train_test_split(
            X_temp, y_temp,
            test_size=(1-val_ratio),
            stratify=y_temp,
            random_state=random_state
        )
        
        # ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ì¬êµ¬ì„±
        train_df = pd.concat([X_train, y_train], axis=1)
        val_df = pd.concat([X_val, y_val], axis=1)
        test_df = pd.concat([X_test, y_test], axis=1)
        
        print(f"âœ… ë¶„í•  ì™„ë£Œ:")
        print(f"   - Train: {len(train_df):,}ëª…")
        print(f"   - Validation: {len(val_df):,}ëª…")
        print(f"   - Test: {len(test_df):,}ëª…")
        
        return train_df, val_df, test_df
    
    def validate_splits(self, original_df, train_df, val_df, test_df):
        """ë¶„í•  ê²°ê³¼ ê²€ì¦"""
        print(f"\nğŸ” ë¶„í•  ê²°ê³¼ ê²€ì¦...")
        
        # ë°ì´í„° ê°œìˆ˜ í™•ì¸
        total_original = len(original_df)
        total_split = len(train_df) + len(val_df) + len(test_df)
        
        print(f"   - ì›ë³¸ ë°ì´í„°: {total_original:,}ëª…")
        print(f"   - ë¶„í•  ë°ì´í„° í•©ê³„: {total_split:,}ëª…")
        
        if total_original != total_split:
            print(f"   âŒ ë°ì´í„° ì†ì‹¤ ë°œìƒ: {total_original - total_split:,}ëª…")
        else:
            print(f"   âœ… ë°ì´í„° ì†ì‹¤ ì—†ìŒ")
        
        # ê° ì„¸íŠ¸ë³„ í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸
        datasets = [("Train", train_df), ("Validation", val_df), ("Test", test_df)]
        
        print(f"\n   í´ë˜ìŠ¤ ë¶„í¬ ë¹„êµ:")
        for name, data in datasets:
            if self.target_column in data.columns:
                mortality_rate = data[self.target_column].mean()
                print(f"   - {name}: {mortality_rate:.1%}")
        
        return True
    
    def save_splits(self, train_df, val_df, test_df):
        """ë¶„í• ëœ ë°ì´í„° ì €ì¥"""
        print(f"\nğŸ’¾ ë¶„í•  ë°ì´í„° ì €ì¥ ì¤‘...")
        
        datasets = {
            'train': train_df,
            'validation': val_df,
            'test': test_df
        }
        
        saved_files = {}
        
        for name, df in datasets.items():
            filename = f"mimic_mortality_{name}.csv"
            filepath = self.output_path / filename
            df.to_csv(filepath, index=False)
            saved_files[name] = filepath
            print(f"   âœ… {name}: {filepath}")
        
        return saved_files
    
    def save_split_summary(self, original_df, train_df, val_df, test_df, saved_files):
        """ë¶„í•  ìš”ì•½ ì •ë³´ ì €ì¥"""
        summary_file = self.output_path / "split_summary.txt"
        
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write("ë°ì´í„° ë¶„í•  ìš”ì•½\n")
            f.write("=" * 50 + "\n")
            f.write(f"ë¶„í•  ì¼ì‹œ: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("ë¶„í•  ë°©ë²•: ì¸µí™” ìƒ˜í”Œë§ (Stratified Sampling)\n")
            f.write("ë¶„í•  ë¹„ìœ¨: Train 60% : Validation 20% : Test 20%\n")
            f.write("ì¸µí™” ê¸°ì¤€: 48ì‹œê°„ ì‚¬ë§ë¥  (mortality_48h)\n\n")
            
            f.write("ë¶„í•  ê²°ê³¼:\n")
            f.write(f"- ì›ë³¸ ë°ì´í„°: {len(original_df):,}ëª…\n")
            f.write(f"- Train ì„¸íŠ¸: {len(train_df):,}ëª… ({len(train_df)/len(original_df):.1%})\n")
            f.write(f"- Validation ì„¸íŠ¸: {len(val_df):,}ëª… ({len(val_df)/len(original_df):.1%})\n")
            f.write(f"- Test ì„¸íŠ¸: {len(test_df):,}ëª… ({len(test_df)/len(original_df):.1%})\n\n")
            
            # í´ë˜ìŠ¤ ë¶„í¬
            f.write("í´ë˜ìŠ¤ ë¶„í¬ (48ì‹œê°„ ì‚¬ë§ë¥ ):\n")
            datasets = [("ì›ë³¸", original_df), ("Train", train_df), ("Validation", val_df), ("Test", test_df)]
            
            for name, df in datasets:
                if self.target_column in df.columns:
                    mortality_rate = df[self.target_column].mean()
                    mortality_count = df[self.target_column].sum()
                    f.write(f"- {name}: {mortality_rate:.1%} ({mortality_count:,}ëª… ì‚¬ë§)\n")
            
            f.write(f"\nì €ì¥ íŒŒì¼:\n")
            for name, filepath in saved_files.items():
                f.write(f"- {name}: {filepath}\n")
            
            f.write(f"\në‹¤ìŒ ë‹¨ê³„: ë¦¬ìƒ˜í”Œë§ (05_resampling.py)\n")
        
        print(f"   âœ… ë¶„í•  ìš”ì•½: {summary_file}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("âœ‚ï¸ ë°ì´í„° ë¶„í•  ì‹œì‘")
    print("=" * 60)
    
    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ì°¾ê¸°
    project_root = Path(__file__).parent.parent
    
    # ê²½ë¡œ ì„¤ì • - ìƒëŒ€ ê²½ë¡œ ì‚¬ìš©
    input_path = project_root / "dataset" / "1_cleaned" / "mimic_mortality_cleaned.csv"
    output_path = project_root / "dataset" / "2_split"
    
    # ë°ì´í„° ë¶„í• ê¸° ì´ˆê¸°í™”
    splitter = DataSplitter(input_path, output_path)
    
    # 1. ë°ì´í„° ë¡œë“œ
    df = splitter.load_data()
    
    # 2. ì›ë³¸ ë¶„í¬ ë¶„ì„
    splitter.analyze_distribution(df, "ì›ë³¸ ë°ì´í„° ë¶„í¬")
    
    # 3. ì¸µí™” ë¶„í• 
    train_df, val_df, test_df = splitter.stratified_split(df)
    
    # 4. ë¶„í•  ê²°ê³¼ ê²€ì¦
    splitter.validate_splits(df, train_df, val_df, test_df)
    
    # 5. ê° ì„¸íŠ¸ë³„ ë¶„í¬ í™•ì¸
    for name, data in [("Train", train_df), ("Validation", val_df), ("Test", test_df)]:
        splitter.analyze_distribution(data, f"{name} ì„¸íŠ¸ ë¶„í¬")
    
    # 6. ë°ì´í„° ì €ì¥
    saved_files = splitter.save_splits(train_df, val_df, test_df)
    
    # 7. ìš”ì•½ ì •ë³´ ì €ì¥
    splitter.save_split_summary(df, train_df, val_df, test_df, saved_files)
    
    print("\n" + "=" * 60)
    print("âœ… ë°ì´í„° ë¶„í•  ì™„ë£Œ!")
    print(f"   ğŸ“ ì €ì¥ ìœ„ì¹˜: {output_path}")
    print("ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„: 05_resampling.py ì‹¤í–‰")
    print("=" * 60)

if __name__ == "__main__":
    main()

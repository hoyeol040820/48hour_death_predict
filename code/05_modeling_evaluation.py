#!/usr/bin/env python3
"""
ëª¨ë¸ë§ ë° í‰ê°€
- ë‹¤ì–‘í•œ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ ë° ì„±ëŠ¥ í‰ê°€
- ëª¨ë¸: Logistic Regression, SVC, Random Forest, XGBoost, LightGBM, Extra Trees
- í‰ê°€ ì§€í‘œ: Accuracy, Precision, Recall, F1-Score, ROC-AUC, PR-AUC
"""

import pandas as pd
import numpy as np
from pathlib import Path
import joblib
import warnings
warnings.filterwarnings('ignore')

# ë¨¸ì‹ ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    roc_auc_score, average_precision_score, confusion_matrix,
    classification_report, roc_curve, precision_recall_curve
)
import xgboost as xgb
import lightgbm as lgb

class ModelTrainer:
    def __init__(self, input_path, output_path):
        self.input_path = Path(input_path)
        self.output_path = Path(output_path)
        self.output_path.mkdir(exist_ok=True)
        
        self.models_path = self.output_path / "models"
        self.models_path.mkdir(exist_ok=True)
        
        self.target_column = 'mortality_48h'
        self.results = []
        
    def define_models(self):
        """ì‚¬ìš©í•  ëª¨ë¸ë“¤ ì •ì˜"""
        self.models = {
            'Logistic_Regression': LogisticRegression(
                random_state=42, max_iter=1000, class_weight='balanced'
            ),
            'SVC': SVC(
                random_state=42, probability=True, class_weight='balanced'
            ),
            'Random_Forest': RandomForestClassifier(
                n_estimators=100, random_state=42, class_weight='balanced', n_jobs=-1
            ),
            'XGBoost': xgb.XGBClassifier(
                random_state=42, eval_metric='logloss', use_label_encoder=False
            ),
            'LightGBM': lgb.LGBMClassifier(
                random_state=42, verbosity=-1, class_weight='balanced'
            ),
            'Extra_Trees': ExtraTreesClassifier(
                n_estimators=100, random_state=42, class_weight='balanced', n_jobs=-1
            )
        }
        
        print(f"âœ… ì •ì˜ëœ ëª¨ë¸: {list(self.models.keys())}")
        
    def load_resampling_data(self, method='smote'):
        """ë¦¬ìƒ˜í”Œë§ëœ ë°ì´í„° ë˜ëŠ” ì›ë³¸ ë°ì´í„° ë¡œë“œ"""
        print(f"ğŸ“‚ {method.upper()} ë°ì´í„° ë¡œë”© ì¤‘...")
        
        if method == 'original':
            # ë¦¬ìƒ˜í”Œë§ëœ original ë°ì´í„° (3_resampled/original/)
            data_path = self.input_path / method
        else:
            # ë¦¬ìƒ˜í”Œë§ëœ ë°ì´í„°
            data_path = self.input_path / method
        
        train_df = pd.read_csv(data_path / "mimic_mortality_train.csv")
        val_df = pd.read_csv(data_path / "mimic_mortality_validation.csv")
        test_df = pd.read_csv(data_path / "mimic_mortality_test.csv")
        
        print(f"âœ… Train: {train_df.shape}, Val: {val_df.shape}, Test: {test_df.shape}")
        
        # í´ë˜ìŠ¤ ë¶„í¬ ì¶œë ¥
        train_mortality = train_df[self.target_column].mean()
        print(f"   Train ì‚¬ë§ë¥ : {train_mortality:.1%}")
        
        return train_df, val_df, test_df
    
    def preprocess_data(self, train_df, val_df, test_df):
        """ë°ì´í„° ì „ì²˜ë¦¬"""
        print("ğŸ”„ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
        
        # ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±° (ID ì»¬ëŸ¼ë“¤)
        id_columns = ['subject_id', 'hadm_id', 'stay_id']
        existing_id_cols = [col for col in id_columns if col in train_df.columns]
        
        # íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬
        X_train = train_df.drop(columns=existing_id_cols + [self.target_column])
        y_train = train_df[self.target_column]
        
        X_val = val_df.drop(columns=existing_id_cols + [self.target_column])
        y_val = val_df[self.target_column]
        
        X_test = test_df.drop(columns=existing_id_cols + [self.target_column])
        y_test = test_df[self.target_column]
        
        # ë¬¸ìì—´ ì»¬ëŸ¼ ì¸ì½”ë”©
        categorical_columns = X_train.select_dtypes(include=['object']).columns
        label_encoders = {}
        
        if len(categorical_columns) > 0:
            print(f"   ë¬¸ìì—´ ì»¬ëŸ¼ ì¸ì½”ë”©: {list(categorical_columns)}")
            
            for col in categorical_columns:
                le = LabelEncoder()
                
                # Train setìœ¼ë¡œë§Œ fit (ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€)
                le.fit(X_train[col].astype(str))
                
                # Transform - ì²˜ë¦¬ë˜ì§€ ì•Šì€ ê°’ì€ -1ë¡œ ì²˜ë¦¬
                def safe_transform(series, encoder):
                    """ì•ˆì „í•œ ë³€í™˜: ìƒˆë¡œìš´ ì¹´í…Œê³ ë¦¬ëŠ” -1ë¡œ ì²˜ë¦¬"""
                    result = series.astype(str).copy()
                    mask = result.isin(encoder.classes_)
                    
                    # ì•Œë ¤ì§„ ê°’ë§Œ ë³€í™˜
                    result_encoded = np.full(len(result), -1, dtype=int)
                    result_encoded[mask] = encoder.transform(result[mask])
                    
                    return result_encoded
                
                X_train[col] = le.transform(X_train[col].astype(str))
                X_val[col] = safe_transform(X_val[col], le)
                X_test[col] = safe_transform(X_test[col], le)
                
                label_encoders[col] = le
        
        # ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (ë‹¨ìˆœ í‰ê·  ëŒ€ì²´)
        if X_train.isnull().any().any():
            print("   ê²°ì¸¡ì¹˜ í‰ê·  ëŒ€ì²´")
            for col in X_train.columns:
                if X_train[col].isnull().any():
                    mean_val = X_train[col].mean()
                    X_train[col].fillna(mean_val, inplace=True)
                    X_val[col].fillna(mean_val, inplace=True)
                    X_test[col].fillna(mean_val, inplace=True)
        
        # ìŠ¤ì¼€ì¼ë§ (SVCìš©)
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_val_scaled = scaler.transform(X_val)
        X_test_scaled = scaler.transform(X_test)
        
        print(f"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ - íŠ¹ì„± ìˆ˜: {X_train.shape[1]}")
        
        return {
            'X_train': X_train, 'y_train': y_train,
            'X_val': X_val, 'y_val': y_val,
            'X_test': X_test, 'y_test': y_test,
            'X_train_scaled': X_train_scaled,
            'X_val_scaled': X_val_scaled,
            'X_test_scaled': X_test_scaled,
            'scaler': scaler,
            'label_encoders': label_encoders
        }
    
    def calculate_metrics(self, y_true, y_pred, y_pred_proba):
        """í‰ê°€ ì§€í‘œ ê³„ì‚°"""
        # í˜¼ë™ í–‰ë ¬
        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
        
        # ê¸°ë³¸ ì§€í‘œ
        accuracy = accuracy_score(y_true, y_pred)
        precision = precision_score(y_true, y_pred, zero_division=0)
        recall = recall_score(y_true, y_pred, zero_division=0)
        f1 = f1_score(y_true, y_pred, zero_division=0)
        
        # íŠ¹ì´ë„ (Specificity)
        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
        
        # AUC ì§€í‘œ
        if len(np.unique(y_true)) > 1:
            roc_auc = roc_auc_score(y_true, y_pred_proba)
            pr_auc = average_precision_score(y_true, y_pred_proba)
        else:
            roc_auc = 0
            pr_auc = 0
        
        return {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'specificity': specificity,
            'roc_auc': roc_auc,
            'pr_auc': pr_auc,
            'confusion_matrix': {'TP': tp, 'TN': tn, 'FP': fp, 'FN': fn}
        }
    
    def train_and_evaluate_model(self, model_name, model, data, resampling_method):
        """ê°œë³„ ëª¨ë¸ í•™ìŠµ ë° í‰ê°€"""
        print(f"ğŸ”„ {resampling_method.upper()}-{model_name} í•™ìŠµ ì¤‘...")
        
        try:
            # ëª¨ë¸ë³„ ë°ì´í„° ì„ íƒ
            if model_name == 'SVC':
                X_train, X_val, X_test = data['X_train_scaled'], data['X_val_scaled'], data['X_test_scaled']
            else:
                X_train, X_val, X_test = data['X_train'], data['X_val'], data['X_test']
            
            y_train, y_val, y_test = data['y_train'], data['y_val'], data['y_test']
            
            # í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬ ë¹„í™œì„±í™” (ë¦¬ìƒ˜í”Œë§ìœ¼ë¡œ ì´ë¯¸ ê· í˜• ì¡°ì •ë¨)
            # if model_name == 'XGBoost':
            #     pos_ratio = (y_train == 0).sum() / (y_train == 1).sum()
            #     model.set_params(scale_pos_weight=pos_ratio)
            #     print(f"   XGBoost scale_pos_weight: {pos_ratio:.2f}")
            # elif model_name == 'LightGBM':
            #     if resampling_method == 'original':
            #         # ì›ë³¸ ë°ì´í„°ì˜ ê²½ìš° í´ë˜ìŠ¤ ë¶ˆê· í˜•ì´ ì‹¬í•¨
            #         model.set_params(is_unbalance=True, class_weight='balanced')
            #     else:
            #         model.set_params(is_unbalance=True)
            
            # ëª¨ë“  ëª¨ë¸ì—ì„œ ê¸°ë³¸ ì„¤ì • ì‚¬ìš© (ë¦¬ìƒ˜í”Œë§ì— ì˜ì¡´)
            
            # ëª¨ë¸ í•™ìŠµ
            model.fit(X_train, y_train)
            
            # ëª¨ë¸ ì €ì¥
            model_filename = f"{resampling_method}_{model_name}.pkl"
            model_path = self.models_path / model_filename
            joblib.dump(model, model_path)
            
            # ê²€ì¦ ì„¸íŠ¸ ì˜ˆì¸¡ (ëª¨ë¸ ì„ íƒìš©)
            y_val_pred = model.predict(X_val)
            
            if hasattr(model, 'predict_proba'):
                y_val_proba = model.predict_proba(X_val)[:, 1]
            elif hasattr(model, 'decision_function'):
                y_val_proba = model.decision_function(X_val)
            else:
                y_val_proba = y_val_pred.astype(float)
            
            # ì„±ëŠ¥ ê³„ì‚° (Validation ê¸°ì¤€)
            val_metrics = self.calculate_metrics(y_val, y_val_pred, y_val_proba)
            
            result = {
                'resampling_method': resampling_method,
                'model_name': model_name,
                'val_metrics': val_metrics,  # Validation ê¸°ì¤€ìœ¼ë¡œ ë³€ê²½
                'model_path': str(model_path),
                'feature_count': X_train.shape[1],
                'train_samples': len(y_train)
            }
            
            print(f"âœ… {resampling_method.upper()}-{model_name} ì™„ë£Œ")
            print(f"   Validation ROC-AUC: {val_metrics['roc_auc']:.4f}")
            print(f"   Validation F1-Score: {val_metrics['f1_score']:.4f}")
            
            return result
            
        except Exception as e:
            print(f"âŒ {resampling_method.upper()}-{model_name} ì‹¤íŒ¨: {e}")
            return {
                'resampling_method': resampling_method,
                'model_name': model_name,
                'error': str(e),
                'val_metrics': None
            }
    
    def run_experiments(self):
        """ëª¨ë“  ëª¨ë¸ ì‹¤í—˜ ì‹¤í–‰"""
        print("ğŸš€ ëª¨ë¸ë§ ì‹¤í—˜ ì‹œì‘")
        print("=" * 60)
        
        # ëª¨ë¸ ì •ì˜
        self.define_models()
        
        resampling_methods = ['original', 'smote', 'downsampling']
        
        for method in resampling_methods:
            print(f"\nğŸ“Š {method.upper()} ë°ì´í„°ì…‹ìœ¼ë¡œ ì‹¤í—˜ ì¤‘...")
            
            # ë°ì´í„° ë¡œë“œ
            try:
                train_df, val_df, test_df = self.load_resampling_data(method)
            except Exception as e:
                print(f"âŒ {method} ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
                continue
            
            # ë°ì´í„° ì „ì²˜ë¦¬
            data = self.preprocess_data(train_df, val_df, test_df)
            
            # ê° ëª¨ë¸ í•™ìŠµ
            for model_name, model in self.models.items():
                # ëª¨ë¸ ë³µì‚¬ (ì¬ì‚¬ìš©ì„ ìœ„í•´)
                from sklearn.base import clone
                model_copy = clone(model)
                
                result = self.train_and_evaluate_model(
                    model_name, model_copy, data, method
                )
                self.results.append(result)
        
        print(f"\nâœ… ì „ì²´ ì‹¤í—˜ ì™„ë£Œ! ì´ {len(self.results)}ê°œ ëª¨ë¸")
        print("   - Original(ì›ë³¸): í´ë˜ìŠ¤ ë¶ˆê· í˜• ìƒíƒœ")
        print("   - SMOTE: ì†Œìˆ˜ í´ë˜ìŠ¤ ì˜¤ë²„ìƒ˜í”Œë§")  
        print("   - Downsampling: ë‹¤ìˆ˜ í´ë˜ìŠ¤ ë‹¤ìš´ìƒ˜í”Œë§")
    
    def save_results(self):
        """ê²°ê³¼ ì €ì¥"""
        print("\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘...")
        
        # ì„±ê³µí•œ ì‹¤í—˜ë§Œ í•„í„°ë§
        successful_results = [r for r in self.results if 'error' not in r and r['val_metrics'] is not None]
        
        if not successful_results:
            print("âŒ ì €ì¥í•  ì„±ê³µì ì¸ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ê²°ê³¼ DataFrame ìƒì„±
        rows = []
        for result in successful_results:
            metrics = result['val_metrics']
            row = {
                'resampling_method': result['resampling_method'],
                'model_name': result['model_name'],
                'accuracy': metrics['accuracy'],
                'precision': metrics['precision'],
                'recall': metrics['recall'],
                'f1_score': metrics['f1_score'],
                'specificity': metrics['specificity'],
                'roc_auc': metrics['roc_auc'],
                'pr_auc': metrics['pr_auc'],
                'feature_count': result['feature_count'],
                'train_samples': result['train_samples'],
                'model_path': result['model_path']
            }
            rows.append(row)
        
        results_df = pd.DataFrame(rows)
        
        # ì„±ëŠ¥ ìˆœ ì •ë ¬ (ROC-AUC ê¸°ì¤€)
        results_df = results_df.sort_values('roc_auc', ascending=False)
        
        # CSV ì €ì¥
        results_csv = self.output_path / "modeling_results.csv"
        results_df.to_csv(results_csv, index=False)
        print(f"âœ… ê²°ê³¼ ì €ì¥: {results_csv}")
        
        # ìš”ì•½ ë¦¬í¬íŠ¸
        self.create_summary_report(results_df)
        
        return results_df
    
    def create_summary_report(self, results_df):
        """ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±"""
        summary_file = self.output_path / "modeling_summary.txt"
        
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write("MIMIC-IV 48ì‹œê°„ ì‚¬ë§ë¥  ì˜ˆì¸¡ ëª¨ë¸ë§ ê²°ê³¼\n")
            f.write("=" * 60 + "\n")
            f.write(f"ì‹¤í—˜ ì¼ì‹œ: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("ì‹¤í—˜ ì„¤ì •:\n")
            f.write("- ëª¨ë¸: Logistic Regression, SVC, Random Forest, XGBoost, LightGBM, Extra Trees\n")
            f.write("- ë¦¬ìƒ˜í”Œë§: Original(ì›ë³¸), SMOTE, Downsampling\n")
            f.write("- í‰ê°€: Validation ì„¸íŠ¸ ê¸°ì¤€ (ëª¨ë¸ ì„ íƒìš©)\n")
            f.write("- ì§€í‘œ: ROC-AUC, F1-Score, Precision, Recall, Accuracy\n\n")
            
            # ìµœê³  ì„±ëŠ¥ ëª¨ë¸
            best_model = results_df.iloc[0]
            f.write("ğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸:\n")
            f.write(f"- ëª¨ë¸: {best_model['resampling_method'].upper()}-{best_model['model_name']}\n")
            f.write(f"- ROC-AUC: {best_model['roc_auc']:.4f}\n")
            f.write(f"- F1-Score: {best_model['f1_score']:.4f}\n")
            f.write(f"- Precision: {best_model['precision']:.4f}\n")
            f.write(f"- Recall: {best_model['recall']:.4f}\n\n")
            
            # ë¦¬ìƒ˜í”Œë§ë³„ ìµœê³  ì„±ëŠ¥
            f.write("ë¦¬ìƒ˜í”Œë§ë³„ ìµœê³  ì„±ëŠ¥:\n")
            for method in results_df['resampling_method'].unique():
                method_best = results_df[results_df['resampling_method'] == method].iloc[0]
                f.write(f"- {method.upper()}: {method_best['model_name']} (ROC-AUC: {method_best['roc_auc']:.4f})\n")
            
            f.write(f"\nì „ì²´ ê²°ê³¼: {len(results_df)}ê°œ ëª¨ë¸\n")
            f.write(f"ì €ì¥ëœ ëª¨ë¸: {self.models_path}\n")
            f.write(f"ë‹¤ìŒ ë‹¨ê³„: í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (07_hyperparameter_tuning.py)\n")
        
        print(f"âœ… ìš”ì•½ ë¦¬í¬íŠ¸: {summary_file}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ¤– ëª¨ë¸ë§ ë° í‰ê°€ ì‹œì‘")
    print("=" * 60)
    
    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ì°¾ê¸°
    project_root = Path(__file__).parent.parent
    
    # ê²½ë¡œ ì„¤ì • - ìƒëŒ€ ê²½ë¡œ ì‚¬ìš©
    input_path = project_root / "dataset" / "3_resampled"
    output_path = project_root / "dataset" / "4_modeling"
    
    # ëª¨ë¸ íŠ¸ë ˆì´ë„ˆ ì´ˆê¸°í™”
    trainer = ModelTrainer(input_path, output_path)
    
    # ëª¨ë“  ì‹¤í—˜ ì‹¤í–‰
    trainer.run_experiments()
    
    # ê²°ê³¼ ì €ì¥
    results_df = trainer.save_results()
    
    if results_df is not None:
        print("\n" + "=" * 60)
        print("âœ… ëª¨ë¸ë§ ì™„ë£Œ!")
        print(f"ğŸ† ìµœê³  ì„±ëŠ¥: {results_df.iloc[0]['resampling_method'].upper()}-{results_df.iloc[0]['model_name']}")
        print(f"ğŸ“Š Validation ROC-AUC: {results_df.iloc[0]['roc_auc']:.4f}")
        print(f"ğŸ’¾ ì €ì¥ ìœ„ì¹˜: {output_path}")
        print(f"ğŸ“Š ì´ ì‹¤í—˜: {len(results_df)}ê°œ ëª¨ë¸ (Original + SMOTE + Downsampling)")
        print("ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„: 06_hyperparameter_tuning.py ì‹¤í–‰")
        print("=" * 60)

if __name__ == "__main__":
    main()
